{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network(Multi-Layer Perceptron)\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# Install Tensorflow from the website: https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('musk_csv.csv')\n",
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>conformation_name</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>...</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+1</td>\n",
       "      <td>46</td>\n",
       "      <td>-108</td>\n",
       "      <td>-60</td>\n",
       "      <td>-69</td>\n",
       "      <td>-117</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>-308</td>\n",
       "      <td>52</td>\n",
       "      <td>-7</td>\n",
       "      <td>39</td>\n",
       "      <td>126</td>\n",
       "      <td>156</td>\n",
       "      <td>-50</td>\n",
       "      <td>-112</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+10</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-6</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-59</td>\n",
       "      <td>-2</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>136</td>\n",
       "      <td>169</td>\n",
       "      <td>-61</td>\n",
       "      <td>-136</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+11</td>\n",
       "      <td>46</td>\n",
       "      <td>-194</td>\n",
       "      <td>-145</td>\n",
       "      <td>28</td>\n",
       "      <td>-117</td>\n",
       "      <td>73</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-134</td>\n",
       "      <td>-154</td>\n",
       "      <td>57</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "      <td>165</td>\n",
       "      <td>-67</td>\n",
       "      <td>-145</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+12</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>136</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+13</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>137</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID molecule_name conformation_name  f1   f2   f3  f4   f5  f6  f7  ...  \\\n",
       "0   1      MUSK-211           211_1+1  46 -108  -60 -69 -117  49  38  ...   \n",
       "1   2      MUSK-211          211_1+10  41 -188 -145  22 -117  -6  57  ...   \n",
       "2   3      MUSK-211          211_1+11  46 -194 -145  28 -117  73  57  ...   \n",
       "3   4      MUSK-211          211_1+12  41 -188 -145  22 -117  -7  57  ...   \n",
       "4   5      MUSK-211          211_1+13  41 -188 -145  22 -117  -7  57  ...   \n",
       "\n",
       "   f158  f159  f160  f161  f162  f163  f164  f165  f166  class  \n",
       "0  -308    52    -7    39   126   156   -50  -112    96      1  \n",
       "1   -59    -2    52   103   136   169   -61  -136    79      1  \n",
       "2  -134  -154    57   143   142   165   -67  -145    39      1  \n",
       "3   -60    -4    52   104   136   168   -60  -135    80      1  \n",
       "4   -60    -4    52   104   137   168   -60  -135    80      1  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6598 entries, 0 to 6597\n",
      "Columns: 170 entries, ID to class\n",
      "dtypes: int64(168), object(2)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5581\n",
       "1    1017\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                   0\n",
      "molecule_name        0\n",
      "conformation_name    0\n",
      "f1                   0\n",
      "f2                   0\n",
      "f3                   0\n",
      "f4                   0\n",
      "f5                   0\n",
      "f6                   0\n",
      "f7                   0\n",
      "f8                   0\n",
      "f9                   0\n",
      "f10                  0\n",
      "f11                  0\n",
      "f12                  0\n",
      "f13                  0\n",
      "f14                  0\n",
      "f15                  0\n",
      "f16                  0\n",
      "f17                  0\n",
      "f18                  0\n",
      "f19                  0\n",
      "f20                  0\n",
      "f21                  0\n",
      "f22                  0\n",
      "f23                  0\n",
      "f24                  0\n",
      "f25                  0\n",
      "f26                  0\n",
      "f27                  0\n",
      "                    ..\n",
      "f138                 0\n",
      "f139                 0\n",
      "f140                 0\n",
      "f141                 0\n",
      "f142                 0\n",
      "f143                 0\n",
      "f144                 0\n",
      "f145                 0\n",
      "f146                 0\n",
      "f147                 0\n",
      "f148                 0\n",
      "f149                 0\n",
      "f150                 0\n",
      "f151                 0\n",
      "f152                 0\n",
      "f153                 0\n",
      "f154                 0\n",
      "f155                 0\n",
      "f156                 0\n",
      "f157                 0\n",
      "f158                 0\n",
      "f159                 0\n",
      "f160                 0\n",
      "f161                 0\n",
      "f162                 0\n",
      "f163                 0\n",
      "f164                 0\n",
      "f165                 0\n",
      "f166                 0\n",
      "class                0\n",
      "Length: 170, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=166, units=83, kernel_initializer=\"uniform\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=83, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 83, init = 'uniform', activation = 'relu', input_dim = 166))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 83, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/100\n",
      "4222/4222 [==============================] - 4s 950us/step - loss: 0.3180 - acc: 0.8624 - val_loss: 0.1998 - val_acc: 0.9214\n",
      "Epoch 2/100\n",
      "4222/4222 [==============================] - 1s 182us/step - loss: 0.1351 - acc: 0.9498 - val_loss: 0.1168 - val_acc: 0.9650\n",
      "Epoch 3/100\n",
      "4222/4222 [==============================] - 1s 161us/step - loss: 0.0858 - acc: 0.9709 - val_loss: 0.0812 - val_acc: 0.9754\n",
      "Epoch 4/100\n",
      "4222/4222 [==============================] - 1s 158us/step - loss: 0.0646 - acc: 0.9739 - val_loss: 0.0659 - val_acc: 0.9820\n",
      "Epoch 5/100\n",
      "4222/4222 [==============================] - 1s 169us/step - loss: 0.0414 - acc: 0.9853 - val_loss: 0.0504 - val_acc: 0.9839\n",
      "Epoch 6/100\n",
      "4222/4222 [==============================] - 1s 179us/step - loss: 0.0380 - acc: 0.9877 - val_loss: 0.0493 - val_acc: 0.9782\n",
      "Epoch 7/100\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0256 - acc: 0.9903 - val_loss: 0.0476 - val_acc: 0.9867\n",
      "Epoch 8/100\n",
      "4222/4222 [==============================] - 1s 156us/step - loss: 0.0210 - acc: 0.9924 - val_loss: 0.0548 - val_acc: 0.9811\n",
      "Epoch 9/100\n",
      "4222/4222 [==============================] - 1s 185us/step - loss: 0.0185 - acc: 0.9936 - val_loss: 0.0370 - val_acc: 0.9867\n",
      "Epoch 10/100\n",
      "4222/4222 [==============================] - 1s 166us/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0344 - val_acc: 0.9896\n",
      "Epoch 11/100\n",
      "4222/4222 [==============================] - 1s 178us/step - loss: 0.0122 - acc: 0.9962 - val_loss: 0.0291 - val_acc: 0.9905\n",
      "Epoch 12/100\n",
      "4222/4222 [==============================] - 1s 156us/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0538 - val_acc: 0.9858\n",
      "Epoch 13/100\n",
      "4222/4222 [==============================] - 1s 154us/step - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0443 - val_acc: 0.9848\n",
      "Epoch 14/100\n",
      "4222/4222 [==============================] - 1s 172us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0282 - val_acc: 0.9924\n",
      "Epoch 15/100\n",
      "4222/4222 [==============================] - 1s 164us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.0222 - val_acc: 0.9943\n",
      "Epoch 16/100\n",
      "4222/4222 [==============================] - 1s 180us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0325 - val_acc: 0.9915\n",
      "Epoch 17/100\n",
      "4222/4222 [==============================] - 1s 163us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0247 - val_acc: 0.9924\n",
      "Epoch 18/100\n",
      "4222/4222 [==============================] - 1s 154us/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0331 - val_acc: 0.9915\n",
      "Epoch 19/100\n",
      "4222/4222 [==============================] - 1s 155us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0353 - val_acc: 0.9886\n",
      "Epoch 20/100\n",
      "4222/4222 [==============================] - 1s 154us/step - loss: 0.0166 - acc: 0.9943 - val_loss: 0.0478 - val_acc: 0.9877\n",
      "Epoch 21/100\n",
      "4222/4222 [==============================] - 1s 177us/step - loss: 0.0528 - acc: 0.9851 - val_loss: 0.0340 - val_acc: 0.9886\n",
      "Epoch 22/100\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0233 - val_acc: 0.9934\n",
      "Epoch 23/100\n",
      "4222/4222 [==============================] - 1s 239us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9943\n",
      "Epoch 24/100\n",
      "4222/4222 [==============================] - 1s 215us/step - loss: 6.2543e-04 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9953\n",
      "Epoch 25/100\n",
      "4222/4222 [==============================] - 1s 203us/step - loss: 4.4070e-04 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9953\n",
      "Epoch 26/100\n",
      "4222/4222 [==============================] - 1s 174us/step - loss: 3.2340e-04 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 0.9953\n",
      "Epoch 27/100\n",
      "4222/4222 [==============================] - 1s 166us/step - loss: 2.3821e-04 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9953\n",
      "Epoch 28/100\n",
      "4222/4222 [==============================] - 1s 245us/step - loss: 1.8652e-04 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9953\n",
      "Epoch 29/100\n",
      "4222/4222 [==============================] - 1s 194us/step - loss: 1.5055e-04 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 0.9953\n",
      "Epoch 30/100\n",
      "4222/4222 [==============================] - 1s 158us/step - loss: 1.2486e-04 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9953\n",
      "Epoch 31/100\n",
      "4222/4222 [==============================] - 1s 162us/step - loss: 1.0331e-04 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 0.9953\n",
      "Epoch 32/100\n",
      "4222/4222 [==============================] - 1s 163us/step - loss: 8.7319e-05 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9953\n",
      "Epoch 33/100\n",
      "4222/4222 [==============================] - 1s 172us/step - loss: 7.6026e-05 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 0.9953\n",
      "Epoch 34/100\n",
      "4222/4222 [==============================] - 1s 158us/step - loss: 6.4100e-05 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9953\n",
      "Epoch 35/100\n",
      "4222/4222 [==============================] - 1s 170us/step - loss: 5.6618e-05 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 0.9953\n",
      "Epoch 36/100\n",
      "4222/4222 [==============================] - 1s 173us/step - loss: 4.9614e-05 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 0.9953\n",
      "Epoch 37/100\n",
      "4222/4222 [==============================] - 1s 198us/step - loss: 4.3356e-05 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 0.9953\n",
      "Epoch 38/100\n",
      "4222/4222 [==============================] - 1s 193us/step - loss: 3.8612e-05 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 0.9953\n",
      "Epoch 39/100\n",
      "4222/4222 [==============================] - 1s 173us/step - loss: 3.4182e-05 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9953\n",
      "Epoch 40/100\n",
      "4222/4222 [==============================] - 1s 166us/step - loss: 3.0721e-05 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9953\n",
      "Epoch 41/100\n",
      "4222/4222 [==============================] - 1s 190us/step - loss: 2.7176e-05 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 0.9953\n",
      "Epoch 42/100\n",
      "4222/4222 [==============================] - 1s 237us/step - loss: 2.4289e-05 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9953\n",
      "Epoch 43/100\n",
      "4222/4222 [==============================] - 1s 229us/step - loss: 2.1708e-05 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9953\n",
      "Epoch 44/100\n",
      "4222/4222 [==============================] - 1s 324us/step - loss: 1.9393e-05 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 0.9953\n",
      "Epoch 45/100\n",
      "4222/4222 [==============================] - 1s 229us/step - loss: 1.7190e-05 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 0.9953\n",
      "Epoch 46/100\n",
      "4222/4222 [==============================] - 1s 237us/step - loss: 1.5506e-05 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9953\n",
      "Epoch 47/100\n",
      "4222/4222 [==============================] - 1s 240us/step - loss: 1.4038e-05 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9953\n",
      "Epoch 48/100\n",
      "4222/4222 [==============================] - 1s 199us/step - loss: 1.2646e-05 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 0.9953\n",
      "Epoch 49/100\n",
      "4222/4222 [==============================] - 1s 172us/step - loss: 1.1553e-05 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9953\n",
      "Epoch 50/100\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 1.0656e-05 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9953\n",
      "Epoch 51/100\n",
      "4222/4222 [==============================] - 1s 174us/step - loss: 9.5408e-06 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 0.9953\n",
      "Epoch 52/100\n",
      "4222/4222 [==============================] - 1s 183us/step - loss: 8.6591e-06 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 0.9953\n",
      "Epoch 53/100\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 7.9600e-06 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9953\n",
      "Epoch 54/100\n",
      "4222/4222 [==============================] - 1s 245us/step - loss: 7.2335e-06 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9953\n",
      "Epoch 55/100\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 6.6297e-06 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9953\n",
      "Epoch 56/100\n",
      "4222/4222 [==============================] - 1s 158us/step - loss: 6.0627e-06 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9953\n",
      "Epoch 57/100\n",
      "4222/4222 [==============================] - 1s 158us/step - loss: 5.5578e-06 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "4222/4222 [==============================] - 1s 162us/step - loss: 5.1578e-06 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 0.9953\n",
      "Epoch 59/100\n",
      "4222/4222 [==============================] - 1s 163us/step - loss: 4.7083e-06 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 0.9953\n",
      "Epoch 60/100\n",
      "4222/4222 [==============================] - 1s 244us/step - loss: 4.2819e-06 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9953\n",
      "Epoch 61/100\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 3.9674e-06 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9953\n",
      "Epoch 62/100\n",
      "4222/4222 [==============================] - 1s 205us/step - loss: 3.6330e-06 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 0.9953\n",
      "Epoch 63/100\n",
      "4222/4222 [==============================] - 1s 263us/step - loss: 3.3547e-06 - acc: 1.0000 - val_loss: 0.0374 - val_acc: 0.9953\n",
      "Epoch 64/100\n",
      "4222/4222 [==============================] - 1s 352us/step - loss: 3.0936e-06 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9953\n",
      "Epoch 65/100\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 2.8339e-06 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9953\n",
      "Epoch 66/100\n",
      "4222/4222 [==============================] - 1s 160us/step - loss: 2.6345e-06 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 0.9953\n",
      "Epoch 67/100\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 2.4359e-06 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 0.9953\n",
      "Epoch 68/100\n",
      "4222/4222 [==============================] - 1s 174us/step - loss: 2.2465e-06 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9953\n",
      "Epoch 69/100\n",
      "4222/4222 [==============================] - 1s 181us/step - loss: 2.0922e-06 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 0.9953\n",
      "Epoch 70/100\n",
      "4222/4222 [==============================] - 1s 159us/step - loss: 1.9315e-06 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 0.9953\n",
      "Epoch 71/100\n",
      "4222/4222 [==============================] - 1s 193us/step - loss: 1.7820e-06 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 0.9953\n",
      "Epoch 72/100\n",
      "4222/4222 [==============================] - 1s 241us/step - loss: 1.6580e-06 - acc: 1.0000 - val_loss: 0.0385 - val_acc: 0.9953\n",
      "Epoch 73/100\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 1.5380e-06 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9953\n",
      "Epoch 74/100\n",
      "4222/4222 [==============================] - 1s 161us/step - loss: 1.4314e-06 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 0.9943\n",
      "Epoch 75/100\n",
      "4222/4222 [==============================] - 1s 153us/step - loss: 1.3223e-06 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9953\n",
      "Epoch 76/100\n",
      "4222/4222 [==============================] - 1s 159us/step - loss: 1.2291e-06 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9953\n",
      "Epoch 77/100\n",
      "4222/4222 [==============================] - 1s 159us/step - loss: 1.1474e-06 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9943\n",
      "Epoch 78/100\n",
      "4222/4222 [==============================] - 1s 176us/step - loss: 1.0618e-06 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9953\n",
      "Epoch 79/100\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 9.9311e-07 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 0.9943\n",
      "Epoch 80/100\n",
      "4222/4222 [==============================] - 1s 272us/step - loss: 9.2516e-07 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9953\n",
      "Epoch 81/100\n",
      "4222/4222 [==============================] - 1s 307us/step - loss: 8.7246e-07 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9943\n",
      "Epoch 82/100\n",
      "4222/4222 [==============================] - 1s 198us/step - loss: 8.0579e-07 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9943\n",
      "Epoch 83/100\n",
      "4222/4222 [==============================] - 1s 195us/step - loss: 7.5757e-07 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9943\n",
      "Epoch 84/100\n",
      "4222/4222 [==============================] - 1s 170us/step - loss: 7.0578e-07 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9943\n",
      "Epoch 85/100\n",
      "4222/4222 [==============================] - 1s 179us/step - loss: 6.5803e-07 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9962\n",
      "Epoch 86/100\n",
      "4222/4222 [==============================] - 1s 166us/step - loss: 6.2584e-07 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9943\n",
      "Epoch 87/100\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 5.8048e-07 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9943\n",
      "Epoch 88/100\n",
      "4222/4222 [==============================] - 1s 243us/step - loss: 5.4440e-07 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9943\n",
      "Epoch 89/100\n",
      "4222/4222 [==============================] - 1s 217us/step - loss: 5.1347e-07 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9943 ETA: 1s - loss: 5.2131e-07 -\n",
      "Epoch 90/100\n",
      "4222/4222 [==============================] - 1s 130us/step - loss: 4.8233e-07 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9943\n",
      "Epoch 91/100\n",
      "4222/4222 [==============================] - 1s 137us/step - loss: 4.5850e-07 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9943\n",
      "Epoch 92/100\n",
      "4222/4222 [==============================] - 1s 133us/step - loss: 4.2800e-07 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 0.9943\n",
      "Epoch 93/100\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 4.0580e-07 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 0.9943\n",
      "Epoch 94/100\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 3.8340e-07 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 0.9943\n",
      "Epoch 95/100\n",
      "4222/4222 [==============================] - 1s 198us/step - loss: 3.6183e-07 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 0.9943\n",
      "Epoch 96/100\n",
      "4222/4222 [==============================] - 1s 216us/step - loss: 3.4389e-07 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 0.9943\n",
      "Epoch 97/100\n",
      "4222/4222 [==============================] - 1s 198us/step - loss: 3.2595e-07 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9953\n",
      "Epoch 98/100\n",
      "4222/4222 [==============================] - 1s 195us/step - loss: 3.0808e-07 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 0.9953\n",
      "Epoch 99/100\n",
      "4222/4222 [==============================] - 1s 182us/step - loss: 2.9410e-07 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 0.9943\n",
      "Epoch 100/100\n",
      "4222/4222 [==============================] - 1s 197us/step - loss: 2.8091e-07 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9953\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "history=classifier.fit(X_train, y_train, validation_split =0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x000001EB5BFC5320>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and evaluating the model\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.999, Test: 0.993\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1117,    3],\n",
       "       [   6,  194]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993182\n"
     ]
    }
   ],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.984772\n"
     ]
    }
   ],
   "source": [
    "# precision tp / (tp + fp)\n",
    "pre = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.970000\n"
     ]
    }
   ],
   "source": [
    "# recall: tp / (tp + fn)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.977330\n"
     ]
    }
   ],
   "source": [
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
